# 分布式消息

## Kafka的入门和简单使用

### Kafka概念和入门

Kafka是一种分布式的，基于发布、订阅的消息系统，主要设计目标

1. 以时间复杂度O（1）的方式提供消息持久化的能力，即使对TB以上数据也能保证常数时间复杂度的访问性能。
2. 高吞吐率。即使再非常廉价的商用机器上也能做到单机支持每秒100kb 条以上的消息的传输
3. 支持Kafka Server 间的消息分区，及分布式消费，同时保证每个Partition内的消息顺序传输
4. 同时支持离线数据处理和实时数据处理
5. Scale out:支持在线水平扩展

#### Kafka的基本概念

1. Borker:Kafka集群包含一个或者多个服务器，这种服务器被称为broker
2. Topic:每条发布到Kafka集群的消息都有一个类别，这个类别呗成为Topic. (物理上的topic 的消息分开存储，逻辑上一个topic的消息虽然保存于一个或多个broker上，电脑能过户只需要指定消息的Topic即可生产或消费数据而不必关心数据存于何处)
3. Partition: Partition 是物理上的概念。每个topic 包含一个或多个Partition.
4. producer:
5. Consumer:
6. Consumer Group:每个Consumer属于一个特定的Consumer Group(可为每个Consumer 指定Group name, 若不指定group name,则属于默认的group)

#### 单机部署模式

#### 集群部署模式

Producer, ZooKeeper (Kafka Broker), Consumer

#### Topic 特性

1. 通过partiiotn 增加可扩展性
2. 通过顺序写入高吞吐
3. 多副本增加容错性



### Kafka的简单使用

#### 单机安装部署

1. kafaka安装

   http://kafka.apache.org/downloads

   下载，解压

2. 启动kafaka

   命令进入kafka目录

   修改配置文件 vim config/server.properties

   打开listeners=PLAINTEXT://localhost:9092

   bin/zookepper-server-start.sh config/zookeeper.properties

   bin/kafka-server-start.sh config/server.properties

#### 单机部署测试 

3、命令行操作 

Kafka bin/kafka-topics.sh --zookeeper localhost:2181 --list 

bin/kafka-topics.sh --zookeeper localhost:2181 --create --topic testk --partitions 3 --replicationfactor 1 bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic testk 

bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --from-beginning --topic testk 

bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic testk 

4、简单性能测试 

bin/kafka-producer-perf-test.sh --topic testk --num-records 100000 --record-size 1000 -- throughput 2000 --producer-props bootstrap.servers=localhost:9092 

bin/kafka-consumer-perf-test.sh --bootstrap-server localhost:9092 --topic testk --fetch-size  1048576 --messages 100000 --threads 1

## Kafka的集群配置

2. 清理掉zk上的所有数据，可以删除zk的本地文件或者用ZooInspector 操作

3. 启动3个Kafka:

   三个命令进入Kafka目录，分别执行：

   ./bin/kafaka-server.start.sh kafka9001.properties

   ./bin/kafaka-server.start.sh kafka9002.properties

   ./bin/kafaka-server.start.sh kafka9003.properties

#### 集群与多副本的说明

1. ISR：In-Sync Replica
2. Rebalance:broker 和consumer group 的rebalance
3. 热点分区：大量数据进入同意分区，需要重新平衡

## Kafka的高级特性

#### 生产者-执行步骤

客户端实现序列化，分区，压缩操作

#### 生产者-确认模式

ack=0 只发送，不管有没有写入broker

ack=1: 写入到leader就认为成功

ack=-1/all:写入到最小的副本则认为成功

#### 生产者特征-同步发送

KafkaProducer kafkaProducer = new KafkaProducer(pro); 

ProducerRecord record = new ProducerRecord("topic", "key", "value"); 

Future future = kafkaProducer.send(record); 

//同步发送方法1 Object o = future.get(); 

//同步发送方法2 kafkaProducer.flush()

#### 生产者特征-异步发送

异步发送 pro.put("linger.ms", “1");  

pro.put("batch.size", "10240"); 

KafkaProducer kafkaProducer = new KafkaProducer(pro); 

ProducerRecord record = new ProducerRecord("topic", "key", "value"); 

Future future = kafkaProducer.send(record); 

//异步发送方法1 kafkaProducer.send(record, (metadata, exception) -> { if (exception == null) System.out.println("record = " + record); }); 

//异步发送方法2 kafkaProducer.send(record);



#### 生产者特性-顺序保证 

顺序保证 

pro.put("max.in.flight.requests.per.connection", “1");  

KafkaProducer kafkaProducer = new KafkaProducer(pro); 

ProducerRecord record = new ProducerRecord("topic", "key", "value"); 

Future future = kafkaProducer.send(record); 

//同步发送 kafkaProducer.send(record); 

kafkaProducer.flush();



#### 生产者特性-消息可靠性传递 

pro.put("enable.idempotence","true"); // 此时就会默认把acks设置为

all pro.put("transaction.id","tx0001"); //思考一下，什么是消息的事务？？？ 

try { 

kafkaProducer.beginTransaction(); 

ProducerRecord record = new ProducerRecord("topic", "key", "value"); 

for (int i = 0; i < 100; i++) { 

kafkaProducer.send(record, (metadata, exception) -> { 

if (exception != null) { 

kafkaProducer.abortTransaction(); 

throw new KafkaException(exception.getMessage() + " , data: " + record); } }); } kafkaProducer.commitTransaction(); } 

catch (Throwable e) {  

kafkaProducer.abortTransaction();  

}

## RabbitMQ/RocketMQ

## Pulsar/eip/Camel/Spring Integration